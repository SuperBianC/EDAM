{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "203077dc-9e07-45be-b0d9-8c797390d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/bianhaiyang/projects/baochong/codes/maskRCNNpipline/fullPipeLine/trainMaskrcnnModel/githubVersion/results/extracted-liver/CE144/liverData/'\n",
    "imgs = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0294c84-ae19-4514-ab02-3d6a1c87acdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in imgs:\n",
    "    os.rename(path+im,path+im.replace('nang','CE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "72471064-3269-4f2b-b06b-5ae3809633ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'results/extracted-liver/CE144/liverPredMask/'\n",
    "imgs = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "051a69ce-8e91-487d-8056-1b9ecc65b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in imgs:\n",
    "    os.rename(path+im,path+im.replace('nang','CE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff0c030-00b0-440d-9e01-4251859543e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d55146-0010-4cfc-869e-92fe2ec4977d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2a87c0-268c-49b0-8b17-632e5841488c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.metrics import recall_score\n",
    "import functools\n",
    "import sys\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import transforms as T\n",
    "import re\n",
    "import cv2_util\n",
    "import cv2\n",
    "import processLiver as pl\n",
    "from net.PLM import GRU_with_Attention\n",
    "from dataset.dataset import SliceDataset\n",
    "from utils import *\n",
    "\n",
    "\n",
    "def numericalize_data(targetDict, max_length = 350,dataPading = False, padidx = 4):\n",
    "    DicList = []\n",
    "    for key in list(targetDict.keys()):\n",
    "        first = getDiseaseTypeFromName(key)\n",
    "        numSeq = transNameToNum(targetDict[key])\n",
    "        cl = len(numSeq)\n",
    "        if cl >max_length:\n",
    "            cutting_len = int((cl - max_length)/2)\n",
    "            numSeq = numSeq[cutting_len:cl - cutting_len]\n",
    "        lengthFlag = len(numSeq)\n",
    "        if dataPading and len(numSeq)<max_length:\n",
    "            numSeq += [padidx]*(max_length-len(numSeq))\n",
    "        DicList.append({'name':key,'ids':numSeq,'label':first,'length':lengthFlag})\n",
    "    return DicList\n",
    "\n",
    "def get_instance_segmentation_model(num_classes):\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "    return model\n",
    "\n",
    "def getSegmentationOnePic(image_path,save_path,masklabel_confidence = 0.6):\n",
    "    imm = Image.open(image_path)\n",
    "    imm = np.array(imm)\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    immmm = T.Compose(transforms)(imm,target=False)\n",
    "    model.eval()\n",
    "    prediction = model([immmm[0].to(device)])\n",
    "    labels = prediction[0]['labels']\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    scores = prediction[0]['scores']\n",
    "    scores = scores.cpu().detach().numpy()\n",
    "    masks = prediction[0]['masks']\n",
    "    m1 = masks[0][0].detach().cpu()\n",
    "    m1[m1>=masklabel_confidence]= int(labels[0])\n",
    "    m1[m1<masklabel_confidence] = 0\n",
    "    if save_path:\n",
    "        imageio.imwrite(os.path.join(save_path,'segmentation.png'), m1.astype('uint8'))\n",
    "    return m1\n",
    "\n",
    "def getDiagnosisOnePic(image_path,masklabel_confidence = 0.6):\n",
    "        imm = Image.open(image_path)\n",
    "        imm = np.array(imm)\n",
    "        transforms = []\n",
    "        transforms.append(T.ToTensor())\n",
    "        immmm = T.Compose(transforms)(imm,target=False)\n",
    "        prediction = model([immmm[0].to(device)])\n",
    "        labels = prediction[0]['labels']\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        scores = prediction[0]['scores']\n",
    "        scores = scores.cpu().detach().numpy()\n",
    "        label_idx = [i for i in range(len(scores)) if scores[i] > masklabel_confidence]\n",
    "        if len(label_idx) == 0:\n",
    "            name = 'norm'\n",
    "        else:\n",
    "            scs = scores.tolist()\n",
    "            name = names.get(str(labels[scs.index(max(scs))].item()))\n",
    "        return name\n",
    "\n",
    "def diagnose_one_person(CT_iamge_folder,model,masklabel_confidence):\n",
    "    names = {'0': 'norm', '1': 'CE','2':'AE','3':'HC'}\n",
    "    lst = os.listdir(CT_iamge_folder)\n",
    "    print('Current patient path',CT_iamge_folder)\n",
    "    lst.sort(key=lambda l: int(re.findall('\\d+',l.split('_')[-1])[0]))\n",
    "    imgss = lst\n",
    "    people_sli = []\n",
    "    for pickOne in imgss:\n",
    "        imm = Image.open(os.path.join(CT_iamge_folder,pickOne))\n",
    "        imm = np.array(imm)\n",
    "        transforms = []\n",
    "        transforms.append(T.ToTensor())\n",
    "        immmm = T.Compose(transforms)(imm,target=False)\n",
    "        prediction = model([immmm[0].to(device)])\n",
    "        labels = prediction[0]['labels']\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        scores = prediction[0]['scores']\n",
    "        scores = scores.cpu().detach().numpy()\n",
    "        label_idx = [i for i in range(len(scores)) if scores[i] > masklabel_confidence]\n",
    "        if len(label_idx) == 0:\n",
    "            name = 'norm'\n",
    "        else:\n",
    "            scs = scores.tolist()\n",
    "            name = names.get(str(labels[scs.index(max(scs))].item()))\n",
    "        people_sli.append(name)\n",
    "    return people_sli\n",
    "\n",
    "def diagnose_all_people(patients_folder,model,masklabel_confidence = 0.8):\n",
    "    rootList = os.listdir(patients_folder)\n",
    "    peopleDiagSequence = {}\n",
    "    for rootp in rootList:\n",
    "        personRoot = patients_folder + rootp\n",
    "        people_slis = diagnose_one_person(os.path.join(personRoot,'liverData'),model,masklabel_confidence)\n",
    "        peopleDiagSequence[rootp] = people_slis\n",
    "    print('All slices are diagnosed')\n",
    "    return peopleDiagSequence\n",
    "\n",
    "def diagnosisPatient(dataloader, model, device):\n",
    "    model.eval()\n",
    "    seqAttn = []\n",
    "    seq = []\n",
    "    predicted_classes = []\n",
    "    predicted_scores = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='evaluating...', file=sys.stdout):\n",
    "            ids = batch['ids'].to(device)\n",
    "            seq.append(ids)\n",
    "            length = batch['length']\n",
    "            label = batch['label'].to(device)\n",
    "            attenW, prediction = model(ids, length)\n",
    "            attenW = attenW.squeeze(2).squeeze(0)\n",
    "            seqAttn.append(attenW)\n",
    "            predicted_score = prediction.cpu().squeeze(0).numpy()\n",
    "            predicted_scores.append(predicted_score)\n",
    "            predicted_class = int(prediction.argmax(dim=-1).squeeze(0).cpu())\n",
    "        predicted_classes.append(predicted_class)\n",
    "        predScores = torch.softmax(torch.tensor(predicted_scores),1)\n",
    "        predScores = np.around(np.array(predScores.tolist()),3)\n",
    "        for pss,pcs in zip(predScores, predicted_classes):\n",
    "            print('the patient is predicted as {} with confidenct {}'.format(transNumToStandardName([pcs])[0],pss[pcs]))\n",
    "    return seq,seqAttn\n",
    "\n",
    "def show_slice_attention_map(seq,seqAttn):\n",
    "    num = 0\n",
    "    print('slice-attention map for this patient')\n",
    "    plt.figure(figsize = ([2,2]))\n",
    "    ax = sns.heatmap([np.array([0,1,2,3])],square=True,cbar = False,linewidths=0.1,cmap = 'Accent',vmax=4,vmin=0)\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.xticks(ticks=list([0.5,1.5,2.5,3.5]),labels=['normal','CE','AE','HC'])\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.yticks([])\n",
    "    plt.figure(figsize=[20,2])\n",
    "    plt.subplot(2,1,1)\n",
    "    ax = sns.heatmap([seq[num].detach().cpu()[0].numpy()],square=False,cbar = False,linewidths=0.1,cmap = 'Accent',vmax=4,vmin=0)\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks([])\n",
    "    plt.subplot(2,1,2)\n",
    "    sns.heatmap([seqAttn[num].detach().cpu().numpy()],square=False,linewidths=0,cmap = 'Reds',cbar = False,)\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "\n",
    "def show_salience_segmentation(image_path,liverPred_path): \n",
    "    dataSlice = np.array(Image.open(image_path))\n",
    "    liverPred = np.array(Image.open(liverPred_path))\n",
    "    slice_lesion_segmentation = getSegmentationOnePic(image_path,save_path=None)\n",
    "    #检测所有图形的轮廓\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.subplots_adjust(wspace = 0.03, hspace =0) ## 子图间距\n",
    "    img_cv = np.array(np2cv2(dataSlice),'uint8')\n",
    "    color=(54, 115, 104)\n",
    "    color2=hex2rgb(0xBDD2B6)\n",
    "    color_tumor = hex2rgb(0xFFAB4C)\n",
    "    alpha = 0.4\n",
    "    contours_tumor_ground = getContour(np.array(Image.open(image_path)))\n",
    "    contours_liver_pred = getContour(liverPred)\n",
    "    contours_tumor_pred = getContour(slice_lesion_segmentation)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(dataSlice,cmap = 'gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    dst = img_cv.copy()\n",
    "    # cv2.drawContours(dst, contours, -1, color, -1)\n",
    "    cv2.drawContours(dst, contours_tumor_pred, -1, color_tumor, -1)\n",
    "    tmp_dst = dst.copy()\n",
    "    dst = img_cv.copy()\n",
    "    dst1 = cv2.addWeighted(dst,alpha,tmp_dst,1-alpha,0)\n",
    "    cv2.drawContours(dst1, contours_liver_pred, -1, color2, 2)\n",
    "    plt.imshow(dst1)\n",
    "\n",
    "### load slice-level model\n",
    "device = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "num_classes = 4\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "save = torch.load('model/pretrained/slice-level-prediction.pth') \n",
    "model.load_state_dict(save['model'])\n",
    "md = model.to(device)\n",
    "me = model.eval()\n",
    "\n",
    "pl.extractLiver_OnePerson('data-input/patient-example/CE144.nii','results/liver-segmentation/CE144_pred.nii.gz','results/extracted-liver/','CE144')\n",
    "\n",
    "test_path = 'results/extracted-liver/'\n",
    "testExample = diagnose_all_people(test_path,model,masklabel_confidence=0.6)\n",
    "# with open(\"testDictexample.pkl\", \"wb\") as tf:\n",
    "#     pickle.dump(testExample,tf,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "### load GRU model\n",
    "maxLen = 230\n",
    "vocab_size = 5\n",
    "embedding_dim = 5 \n",
    "hidden_dim = 50\n",
    "output_dim = 4\n",
    "n_layers = 1\n",
    "bidirectional = True\n",
    "dropout_rate = 0\n",
    "pad_index = 4\n",
    "\n",
    "# with open(\"testDictexample.pkl\", \"rb\") as tf:\n",
    "#     testExampleSeq = pickle.load(tf)\n",
    "\n",
    "testExampleSeq = testExample\n",
    "modelGRU_atten = GRU_with_Attention(vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout_rate, \n",
    "             pad_index = pad_index)\n",
    "save = torch.load('model/pretrained/patient-level-diagnosis.pt',map_location=torch.device('cpu')) \n",
    "deviceInfer = torch.device('cuda:1') if torch.cuda.is_available() else torch.device('cpu')\n",
    "modelGRU_atten.load_state_dict(save)\n",
    "modelGRU_atten.to(deviceInfer)\n",
    "modelGRU_atten.eval()\n",
    "collate = functools.partial(collate, pad_index=pad_index)\n",
    "### test data\n",
    "testDicList = numericalize_data(testExampleSeq,max_length=maxLen,dataPading=False)\n",
    "test_data = SliceDataset(testDicList)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=1, collate_fn=collate,shuffle = False)\n",
    "seq,seqAttn = diagnosisPatient(test_dataloader,modelGRU_atten,deviceInfer)\n",
    "\n",
    "### slice-attention map\n",
    "show_slice_attention_map(seq,seqAttn)\n",
    "\n",
    "CT_iamge_folder = 'results/extracted-liver/CE144/liverData/'\n",
    "lst = os.listdir(CT_iamge_folder)\n",
    "lst.sort(key=lambda l: int(re.findall('\\d+',l.split('_')[-1])[0]))\n",
    "sal_idx = np.argmax(seqAttn[0].detach().cpu().numpy())\n",
    "image_path = os.path.join('results/extracted-liver/CE144/liverData/',lst[sal_idx])\n",
    "liverPred_path = os.path.join('results/extracted-liver/CE144/liverPredMask/',lst[sal_idx])\n",
    "\n",
    "### show most salient slice and its lesion segmentation and liver segmentation\n",
    "show_salience_segmentation(image_path,liverPred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9c939d-2cba-4abf-8c3f-b3f2764a5d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch37",
   "language": "python",
   "name": "pytorch37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
